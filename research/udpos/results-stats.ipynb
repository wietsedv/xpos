{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# import mplcairo\n",
    "# matplotlib.use(\"module://mplcairo.macosx\")\n",
    "# print(matplotlib.get_backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !coman-python src/results.py udpos -q -mt ft --digest b30906d4 --sort_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"research/udpos/langs-ud.txt\") as f:\n",
    "#     ud_langs = {line.rstrip().split(\" \", maxsplit=1)[0]: line.rstrip().split(\" \", maxsplit=1)[1] for line in f}\n",
    "\n",
    "ud_df = pd.read_csv(\"exports/udpos-langs.csv\")\n",
    "ud_langs = {row[\"language_id\"]: row[\"language\"] for _, row in ud_df.iterrows()}\n",
    "ud_langs_scripts = {row[\"language\"]: row[\"script\"] for _, row in ud_df.iterrows()}\n",
    "\n",
    "wiki_df = pd.read_csv(\"exports/wiki-langs.csv\")\n",
    "wiki_langs = {row[\"language_id\"]: row[\"language\"] for _, row in wiki_df.iterrows()}\n",
    "# wiki_langs_scripts = {row[\"language\"]: row[\"script\"] for _, row in wiki_df.iterrows()}\n",
    "\n",
    "with open(\"research/udpos/fams.txt\") as f:\n",
    "    lang_branches = {line.rstrip().split(\" \", maxsplit=1)[0].replace(\"_\", \" \"): line.rstrip().split(\" \", maxsplit=1)[1] for line in f}\n",
    "\n",
    "lang_fams = {lang: \"Indo-European\" if branch.startswith(\"IE\") else branch for lang, branch in lang_branches.items()}\n",
    "\n",
    "# with open(\"research/udpos/langs-xlmr.txt\") as f:\n",
    "#     model_langs = {line.rstrip().split(\" \", maxsplit=1)[0]: line.rstrip().split(\" \", maxsplit=1)[1] for line in f}\n",
    "\n",
    "# with open(\"research/udpos/langs-xlmr-warn.txt\") as f:\n",
    "#     model_langs_warn = {line.rstrip().split(\" \", maxsplit=1)[0]: line.rstrip().split(\" \", maxsplit=1)[1] for line in f}\n",
    "\n",
    "ldnd_df = pd.read_csv(\"research/udpos/ldnd.csv\", index_col=0)\n",
    "order_df = pd.read_csv(\"research/udpos/word-order.csv\", index_col=1)\n",
    "\n",
    "model_langs_warn = {}\n",
    "\n",
    "ud_lang_names = set(ud_df.language.tolist())\n",
    "model_lang_names = set(wiki_df.language.tolist())\n",
    "model_lang_names_warn = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 94 58 47\n"
     ]
    }
   ],
   "source": [
    "print(len(ud_lang_names), len(model_lang_names), len(ud_lang_names & model_lang_names), len(ud_lang_names - model_lang_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_name</th>\n",
       "      <th>digest</th>\n",
       "      <th>lang_train</th>\n",
       "      <th>lang_pred</th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_type</th>\n",
       "      <th>score</th>\n",
       "      <th>full_train_size</th>\n",
       "      <th>...</th>\n",
       "      <th>lang_train_script</th>\n",
       "      <th>lang_pred_script</th>\n",
       "      <th>script_same</th>\n",
       "      <th>ldnd</th>\n",
       "      <th>sov_order_train</th>\n",
       "      <th>sov_order_pred</th>\n",
       "      <th>sov_order_same</th>\n",
       "      <th>lang_train_script_type</th>\n",
       "      <th>lang_pred_script_type</th>\n",
       "      <th>script_type_same</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>English</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>90.391066</td>\n",
       "      <td>19912</td>\n",
       "      <td>...</td>\n",
       "      <td>latin</td>\n",
       "      <td>latin</td>\n",
       "      <td>True</td>\n",
       "      <td>61.13</td>\n",
       "      <td>SVO</td>\n",
       "      <td>No dominant order</td>\n",
       "      <td>False</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>English</td>\n",
       "      <td>German</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>88.613954</td>\n",
       "      <td>19912</td>\n",
       "      <td>...</td>\n",
       "      <td>latin</td>\n",
       "      <td>latin</td>\n",
       "      <td>True</td>\n",
       "      <td>67.33</td>\n",
       "      <td>SVO</td>\n",
       "      <td>No dominant order</td>\n",
       "      <td>False</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>English</td>\n",
       "      <td>Italian</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>87.774192</td>\n",
       "      <td>19912</td>\n",
       "      <td>...</td>\n",
       "      <td>latin</td>\n",
       "      <td>latin</td>\n",
       "      <td>True</td>\n",
       "      <td>89.88</td>\n",
       "      <td>SVO</td>\n",
       "      <td>SVO</td>\n",
       "      <td>True</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>English</td>\n",
       "      <td>French</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>87.440783</td>\n",
       "      <td>19912</td>\n",
       "      <td>...</td>\n",
       "      <td>latin</td>\n",
       "      <td>latin</td>\n",
       "      <td>True</td>\n",
       "      <td>91.35</td>\n",
       "      <td>SVO</td>\n",
       "      <td>SVO</td>\n",
       "      <td>True</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>90.279240</td>\n",
       "      <td>19912</td>\n",
       "      <td>...</td>\n",
       "      <td>latin</td>\n",
       "      <td>latin</td>\n",
       "      <td>True</td>\n",
       "      <td>94.14</td>\n",
       "      <td>SVO</td>\n",
       "      <td>SVO</td>\n",
       "      <td>True</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>6819</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>Western Armenian</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>71.766482</td>\n",
       "      <td>1543</td>\n",
       "      <td>...</td>\n",
       "      <td>arabic</td>\n",
       "      <td>armenian</td>\n",
       "      <td>False</td>\n",
       "      <td>99.46</td>\n",
       "      <td>SOV</td>\n",
       "      <td>SOV</td>\n",
       "      <td>True</td>\n",
       "      <td>abjad</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>6820</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>Scottish Gaelic</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>48.034398</td>\n",
       "      <td>1543</td>\n",
       "      <td>...</td>\n",
       "      <td>arabic</td>\n",
       "      <td>latin</td>\n",
       "      <td>False</td>\n",
       "      <td>101.36</td>\n",
       "      <td>SOV</td>\n",
       "      <td>VSO</td>\n",
       "      <td>False</td>\n",
       "      <td>abjad</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6821</th>\n",
       "      <td>6821</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>Khunsari</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>52.702703</td>\n",
       "      <td>1543</td>\n",
       "      <td>...</td>\n",
       "      <td>arabic</td>\n",
       "      <td>arabic</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "      <td>SOV</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>abjad</td>\n",
       "      <td>abjad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6822</th>\n",
       "      <td>6822</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>77.083333</td>\n",
       "      <td>1543</td>\n",
       "      <td>...</td>\n",
       "      <td>arabic</td>\n",
       "      <td>hebrew</td>\n",
       "      <td>False</td>\n",
       "      <td>100.13</td>\n",
       "      <td>SOV</td>\n",
       "      <td>SVO</td>\n",
       "      <td>False</td>\n",
       "      <td>abjad</td>\n",
       "      <td>abjad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6824</th>\n",
       "      <td>6824</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>udpos28</td>\n",
       "      <td>1d6ca3e8</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>Chukchi</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>ft</td>\n",
       "      <td>40.333452</td>\n",
       "      <td>1543</td>\n",
       "      <td>...</td>\n",
       "      <td>arabic</td>\n",
       "      <td>cyrillic</td>\n",
       "      <td>False</td>\n",
       "      <td>100.00</td>\n",
       "      <td>SOV</td>\n",
       "      <td>No dominant order</td>\n",
       "      <td>False</td>\n",
       "      <td>abjad</td>\n",
       "      <td>alphabetic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6760 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0             task_type task_name    digest lang_train  \\\n",
       "1              1  token-classification   udpos28  1d6ca3e8    English   \n",
       "2              2  token-classification   udpos28  1d6ca3e8    English   \n",
       "3              3  token-classification   udpos28  1d6ca3e8    English   \n",
       "4              4  token-classification   udpos28  1d6ca3e8    English   \n",
       "5              5  token-classification   udpos28  1d6ca3e8    English   \n",
       "...          ...                   ...       ...       ...        ...   \n",
       "6819        6819  token-classification   udpos28  1d6ca3e8     Uyghur   \n",
       "6820        6820  token-classification   udpos28  1d6ca3e8     Uyghur   \n",
       "6821        6821  token-classification   udpos28  1d6ca3e8     Uyghur   \n",
       "6822        6822  token-classification   udpos28  1d6ca3e8     Uyghur   \n",
       "6824        6824  token-classification   udpos28  1d6ca3e8     Uyghur   \n",
       "\n",
       "             lang_pred          model_id model_type      score  \\\n",
       "1                Dutch  xlm-roberta-base         ft  90.391066   \n",
       "2               German  xlm-roberta-base         ft  88.613954   \n",
       "3              Italian  xlm-roberta-base         ft  87.774192   \n",
       "4               French  xlm-roberta-base         ft  87.440783   \n",
       "5              Spanish  xlm-roberta-base         ft  90.279240   \n",
       "...                ...               ...        ...        ...   \n",
       "6819  Western Armenian  xlm-roberta-base         ft  71.766482   \n",
       "6820   Scottish Gaelic  xlm-roberta-base         ft  48.034398   \n",
       "6821          Khunsari  xlm-roberta-base         ft  52.702703   \n",
       "6822            Hebrew  xlm-roberta-base         ft  77.083333   \n",
       "6824           Chukchi  xlm-roberta-base         ft  40.333452   \n",
       "\n",
       "      full_train_size  ...  lang_train_script  lang_pred_script  script_same  \\\n",
       "1               19912  ...              latin             latin         True   \n",
       "2               19912  ...              latin             latin         True   \n",
       "3               19912  ...              latin             latin         True   \n",
       "4               19912  ...              latin             latin         True   \n",
       "5               19912  ...              latin             latin         True   \n",
       "...               ...  ...                ...               ...          ...   \n",
       "6819             1543  ...             arabic          armenian        False   \n",
       "6820             1543  ...             arabic             latin        False   \n",
       "6821             1543  ...             arabic            arabic         True   \n",
       "6822             1543  ...             arabic            hebrew        False   \n",
       "6824             1543  ...             arabic          cyrillic        False   \n",
       "\n",
       "        ldnd sov_order_train     sov_order_pred sov_order_same  \\\n",
       "1      61.13             SVO  No dominant order          False   \n",
       "2      67.33             SVO  No dominant order          False   \n",
       "3      89.88             SVO                SVO           True   \n",
       "4      91.35             SVO                SVO           True   \n",
       "5      94.14             SVO                SVO           True   \n",
       "...      ...             ...                ...            ...   \n",
       "6819   99.46             SOV                SOV           True   \n",
       "6820  101.36             SOV                VSO          False   \n",
       "6821  100.00             SOV            Unknown          False   \n",
       "6822  100.13             SOV                SVO          False   \n",
       "6824  100.00             SOV  No dominant order          False   \n",
       "\n",
       "     lang_train_script_type  lang_pred_script_type script_type_same  \n",
       "1                alphabetic             alphabetic             True  \n",
       "2                alphabetic             alphabetic             True  \n",
       "3                alphabetic             alphabetic             True  \n",
       "4                alphabetic             alphabetic             True  \n",
       "5                alphabetic             alphabetic             True  \n",
       "...                     ...                    ...              ...  \n",
       "6819                  abjad             alphabetic            False  \n",
       "6820                  abjad             alphabetic            False  \n",
       "6821                  abjad                  abjad             True  \n",
       "6822                  abjad                  abjad             True  \n",
       "6824                  abjad             alphabetic            False  \n",
       "\n",
       "[6760 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 10_000\n",
    "if n_samples < 0:\n",
    "    df = pd.read_csv(f\"exports/udpos-ft-{-n_samples}epoch.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(f\"exports/udpos-ft-{n_samples:0>5}.csv\")\n",
    "\n",
    "size_df = pd.read_csv(\"exports/udpos-sizes-train.csv\", usecols=[\"language\",\"size\"], index_col=\"language\")\n",
    "if n_samples < 0:\n",
    "    df[\"full_train_size\"] = df.lang_train.map(lambda x: size_df.loc[x, \"size\"])\n",
    "    df[\"train_size\"] = df[\"full_train_size\"]\n",
    "else:\n",
    "    df[\"full_train_size\"] = df.lang_train.map(lambda x: size_df.loc[x, \"size\"])\n",
    "    df[\"train_size\"] = df.full_train_size.map(lambda x: min(x, n_samples))  # type: ignore\n",
    "\n",
    "df[\"train_size_tiny\"] = df.train_size < 200\n",
    "    \n",
    "df[\"num_samples\"] = n_samples\n",
    "df[\"sampling\"] = \"none\" if n_samples < 0 else df.train_size.map(lambda x: \"undersampled\" if x >= n_samples else \"oversampled\")\n",
    "df[\"sampling\"] = df.sampling.astype(\"category\")\n",
    "\n",
    "df[\"lang_train\"] = df.lang_train.map(ud_langs.get)\n",
    "df[\"lang_pred\"] = df.lang_pred.map(ud_langs.get)\n",
    "df[\"lang_train_pred\"] = df[\"lang_train\"] + df[\"lang_pred\"]\n",
    "df[\"lang_same\"] = df[\"lang_train\"] == df[\"lang_pred\"]\n",
    "\n",
    "df[\"lang_train_family\"] = df.lang_train.map(lang_fams.get)\n",
    "df[\"lang_pred_family\"] = df.lang_pred.map(lang_fams.get)\n",
    "df[\"family_same\"] = df[\"lang_train_family\"] == df[\"lang_pred_family\"]\n",
    "\n",
    "df[\"lang_train_branch\"] = df.lang_train.map(lang_branches.get)\n",
    "df[\"lang_pred_branch\"] = df.lang_pred.map(lang_branches.get)\n",
    "df[\"branch_same\"] = df[\"lang_train_branch\"] == df[\"lang_pred_branch\"]\n",
    "\n",
    "df[\"lang_train_ie\"] = df.lang_train.map(lambda x: lang_fams.get(x).startswith(\"IE\"))\n",
    "df[\"lang_pred_ie\"] = df.lang_pred.map(lambda x: lang_fams.get(x).startswith(\"IE\"))\n",
    "df[\"ie_same\"] = df[\"lang_train_ie\"] == df[\"lang_pred_ie\"]\n",
    "\n",
    "df[\"lang_train_pretrained\"] = df.lang_train.map(lambda x: x in model_lang_names)\n",
    "df[\"lang_pred_pretrained\"] = df.lang_pred.map(lambda x: x in model_lang_names)\n",
    "df[\"pretrained_same\"] = df[\"lang_train_pretrained\"] == df[\"lang_pred_pretrained\"]\n",
    "\n",
    "df[\"related_train_pretrained\"] = df.lang_train.map(lambda x: x in model_lang_names or x in [\"Western Armenian\", \"Faroese\", \"Old East Slavic\"])\n",
    "df[\"related_pred_pretrained\"] = df.lang_pred.map(lambda x: x in model_lang_names or x in [\"Western Armenian\", \"Faroese\", \"Old East Slavic\"])\n",
    "\n",
    "df[\"lang_train_script\"] = df.lang_train.map(ud_langs_scripts.get)\n",
    "df[\"lang_pred_script\"] = df.lang_pred.map(ud_langs_scripts.get)\n",
    "df[\"script_same\"] = df[\"lang_train_script\"] == df[\"lang_pred_script\"]\n",
    "\n",
    "\n",
    "def get_ldnd(x):\n",
    "    try:\n",
    "        y = ldnd_df.loc[x.lang_train, x.lang_pred]\n",
    "    except KeyError:\n",
    "        y = 100\n",
    "    if pd.isnull(y):\n",
    "        return 0\n",
    "    return y\n",
    "df[\"ldnd\"] = df.apply(get_ldnd, axis=1)\n",
    "\n",
    "def get_sov(x):\n",
    "    try:\n",
    "        return order_df.loc[x.lang_train, x.lang_pred].SOV\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "# [\"language\", \"SOV\", \"SV\", \"OV\", \"OOV\", \"AdpNP\", \"GN\", \"AN\", \"DN\", \"NN\", \"RN\", \"QP\"]\n",
    "df[\"sov_order_train\"] = df.lang_train.map(lambda x: order_df.SOV.get(x, \"Unknown\"))\n",
    "df[\"sov_order_pred\"] = df.lang_pred.map(lambda x: order_df.SOV.get(x, \"Unknown\"))\n",
    "df[\"sov_order_same\"] = df[\"sov_order_train\"] == df[\"sov_order_pred\"]\n",
    "\n",
    "script_types = {\n",
    "    \"latin\": \"alphabetic\",\n",
    "    \"cyrillic\": \"alphabetic\",\n",
    "    \"armenian\": \"alphabetic\",\n",
    "    \"hangul\": \"logosyllabic\",\n",
    "    \"chinese\": \"logosyllabic\",\n",
    "    \"greek\": \"alphabetic\",\n",
    "    \"devanagari\": \"abugida\",\n",
    "    \"tamil\": \"abugida\",\n",
    "    \"arabic\": \"abjad\",\n",
    "    \"kana\": \"logosyllabic\",\n",
    "    \"telugu\": \"abugida\",\n",
    "    \"hebrew\": \"abjad\",\n",
    "    \"syriac\": \"abjad\",\n",
    "    \"thai\": \"abjad\",\n",
    "    \"old turkic\": \"alphabetic\",\n",
    "}\n",
    "\n",
    "df[\"lang_train_script_type\"] = df.lang_train_script.map(lambda x: script_types[x])\n",
    "df[\"lang_pred_script_type\"] = df.lang_pred_script.map(lambda x: script_types[x])\n",
    "df[\"script_type_same\"] = df[\"lang_train_script_type\"] == df[\"lang_pred_script_type\"]\n",
    "\n",
    "df = df.loc[~df.lang_same]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Old East Slavic', 'Faroese', 'Western Armenian'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.lang_train_pretrained != df.related_train_pretrained].lang_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kj/023mq4990fl0ly4ccp3rkhfm0000gn/T/ipykernel_49743/2584697920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixedlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"score ~ family_same + lang_pred_pretrained + pretrained_same + lang_pred_ie + ie_same + sov_order_pred + sov_order_same + ldnd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lang_pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixedlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"score ~ lang_pred_pretrained + pretrained_same + lang_pred_ie + ie_same + sov_order_pred + sov_order_same + ldnd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lang_pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# anova_lm(m0, m1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, reml, niter_sa, do_cg, fe_pen, cov_pen, free, full_output, method, **fit_kwargs)\u001b[0m\n\u001b[1;32m   2189\u001b[0m             \u001b[0;31m# Try optimizing one or more times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2191\u001b[0;31m                 rslt = super(MixedLM, self).fit(start_params=packed,\n\u001b[0m\u001b[1;32m   2192\u001b[0m                                                 \u001b[0mskip_hessian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                                                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n\u001b[0m\u001b[1;32m    564\u001b[0m                                                        \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                                                        \u001b[0mhessian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_funcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0m\u001b[1;32m    242\u001b[0m                              \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                              \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n\u001b[0m\u001b[1;32m    652\u001b[0m                                      \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                                      \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    195\u001b[0m             'maxls': maxls}\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0m\u001b[1;32m    198\u001b[0m                            **opts)\n\u001b[1;32m    199\u001b[0m     d = {'grad': res['jac'],\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[1;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mloglike\u001b[0;34m(self, params, profile_fe)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0;31m# Move to the profile set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprofile_fe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0mfe_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fe_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cov_sing\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mget_fe_params\u001b[0;34m(self, cov_re, vcomp, tol)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0mfe_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m             \u001b[0mfe_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfe_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/xling-benchmarks-082a4773/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "m0 = smf.mixedlm(f\"score ~ family_same + lang_pred_pretrained + pretrained_same + lang_pred_ie + ie_same + sov_order_pred + sov_order_same + ldnd\", groups=df[\"lang_pred\"], data=df).fit(method=[\"lbfgs\"])\n",
    "m1 = smf.mixedlm(f\"score ~ lang_pred_pretrained + pretrained_same + lang_pred_ie + ie_same + sov_order_pred + sov_order_same + ldnd\", groups=df[\"lang_pred\"], data=df).fit(method=[\"lbfgs\"])\n",
    "\n",
    "# anova_lm(m0, m1)\n",
    "m0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_pred_script</th>\n",
       "      <th>lang_pred_script_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>latin</td>\n",
       "      <td>alphabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cyrillic</td>\n",
       "      <td>alphabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>armenian</td>\n",
       "      <td>alphabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hangul</td>\n",
       "      <td>logosyllabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>syriac</td>\n",
       "      <td>abjad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>chinese</td>\n",
       "      <td>logosyllabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>greek</td>\n",
       "      <td>alphabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>devanagari</td>\n",
       "      <td>abugida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>thai</td>\n",
       "      <td>abjad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tamil</td>\n",
       "      <td>abugida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>arabic</td>\n",
       "      <td>abjad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>kana</td>\n",
       "      <td>logosyllabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>telugu</td>\n",
       "      <td>abugida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>old turkic</td>\n",
       "      <td>alphabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>hebrew</td>\n",
       "      <td>abjad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lang_pred_script lang_pred_script_type\n",
       "1              latin            alphabetic\n",
       "6           cyrillic            alphabetic\n",
       "12          armenian            alphabetic\n",
       "30            hangul          logosyllabic\n",
       "35            syriac                 abjad\n",
       "39           chinese          logosyllabic\n",
       "45             greek            alphabetic\n",
       "49        devanagari               abugida\n",
       "50              thai                 abjad\n",
       "57             tamil               abugida\n",
       "62            arabic                 abjad\n",
       "66              kana          logosyllabic\n",
       "81            telugu               abugida\n",
       "94        old turkic            alphabetic\n",
       "102           hebrew                 abjad"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, [\"lang_pred_script\", \"lang_pred_script_type\"]].drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2280de6b2ecdb622479fb51b868d1a706a1e105407067af22ca9e6cc72e33caf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('xling-benchmarks-082a4773': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
